{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unit_test_train_subloss (generic function with 2 methods)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Test,TimerOutputs,Printf\n",
    "using MatrixCompletion.Losses\n",
    "using MatrixCompletion.Concepts\n",
    "import Random,Distributions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function forword_map(distribution::AbstractPoisson,\n",
    "                         canonical_parameter::Array{Float64,1};\n",
    "                         non_canonical_parameter::Union{Array{Float64},Nothing} = nothing,\n",
    "                         non_canonical_map = nothing)\n",
    "    if !isnothing(non_canonical_parameter)\n",
    "        ## TODO\n",
    "    end\n",
    "    return exp.(canonical_parameter)    \n",
    "end\n",
    "\n",
    "\n",
    "function predict(distribution::AbstractPoisson,input::Array{Float64,1};\n",
    "                 non_canonical_prediction_map = nothing)\n",
    "    if !isnothing(non_canonical_prediction_map)\n",
    "        #TODO\n",
    "    end\n",
    "    return round.(input)\n",
    "end\n",
    "\n",
    "\n",
    "function forword_map(distribution::AbstractGamma,\n",
    "                         canonical_parameter::Array{Float64,1};\n",
    "                         non_canonical_parameter::Union{Array{Float64},Nothing} = nothing,\n",
    "                         non_canonical_map = nothing)\n",
    "    if !isnothing(non_canonical_parameter)\n",
    "        ## TODO\n",
    "    end\n",
    "    return canonical_parameter\n",
    "end\n",
    "\n",
    "\n",
    "function predict(distribution::AbstractGamma,input::Array{Float64,1};\n",
    "                 non_canonical_prediction_map = nothing)\n",
    "    if !isnothing(non_canonical_prediction_map)\n",
    "        #TODO\n",
    "    end\n",
    "    return input # \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function unit_test_train_subloss(dist       = AbstractPoisson();\n",
    "                                 gradient_eval      = Losses.provide(Loss{AbstractPoisson}()),\n",
    "                                 input_distribution = Distributions.Poisson(5),\n",
    "                                 input_size         = 500,\n",
    "                                 ρ = 0,\n",
    "                                 step_size = 0.1,\n",
    "                                 max_iter = 100)\n",
    "    y = Random.rand(input_distribution, input_size) * 1.0\n",
    "    mle_x = train(gradient_eval,\n",
    "                  fx    = rand(input_size),\n",
    "                  y     = y,\n",
    "                  c     = zeros(input_size),\n",
    "                  ρ     = ρ,\n",
    "                  iter  = max_iter,\n",
    "                  γ     = step_size);\n",
    "    prediction = predict(dist,forword_map(dist,mle_x))\n",
    "    errRate = sum(abs.(prediction .- y) .> 1) / input_size;\n",
    "    return 1- errRate;\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loss{AbstractGamma}()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = AbstractGamma()\n",
    "input_distribution = Distributions.Gamma(5,10)\n",
    "input_size = 500\n",
    "y = Random.rand(input_distribution, input_size) * 1.0\n",
    "ρ = 0\n",
    "step_size = 0.01\n",
    "max_iter = 200\n",
    "gradient_eval = Loss{AbstractGamma}()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Array{Float64,1}:\n",
       " 28.57301273199349 \n",
       " 29.246725486626875\n",
       " 90.20126555332095 \n",
       " 49.362184616472774\n",
       " 77.32505013712259 \n",
       " 29.550417294715338\n",
       " 61.35045230198071 \n",
       " 27.005744475998064\n",
       " 58.58169878673729 \n",
       " 26.769351285495198\n",
       " 13.07846467227337 \n",
       " 66.05724416658462 \n",
       " 28.116484639658935\n",
       " 59.20697037598515 \n",
       " 57.97443440137112 \n",
       " 67.06547127849412 \n",
       " 39.29582501500866 \n",
       " 68.88776982811092 \n",
       " 53.90819414197207 \n",
       " 60.61227018667597 "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MatrixCompletion.Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Array{Float64,1}:\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6\n",
       " 2.0253958398202116e-6"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mle_x = train(\n",
    "                  gradient_eval,\n",
    "                  fx    = ones(input_size),\n",
    "                  y     = y,\n",
    "                  c     = zeros(input_size),\n",
    "                  ρ     = ρ,\n",
    "                  iter  = 200,\n",
    "                  γ     = 0.1,\n",
    "                  verbose = false);\n",
    "-1 ./ mle_x[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching -(::Array{Float64,2}, ::Float64)\nClosest candidates are:\n  -(!Matched::Float64, ::Float64) at float.jl:397\n  -(!Matched::Complex{Bool}, ::Real) at complex.jl:298\n  -(!Matched::Missing, ::Number) at missing.jl:97\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching -(::Array{Float64,2}, ::Float64)\nClosest candidates are:\n  -(!Matched::Float64, ::Float64) at float.jl:397\n  -(!Matched::Complex{Bool}, ::Real) at complex.jl:298\n  -(!Matched::Missing, ::Number) at missing.jl:97\n  ...",
      "",
      "Stacktrace:",
      " [1] #trainGamma#64(::Int64, ::Float64, ::Function, ::Array{Float64,2}, ::Array{Float64,1}, ::Int64, ::Array{Float64,2}, ::Float64) at ./In[108]:38",
      " [2] (::getfield(Main, Symbol(\"#kw##trainGamma\")))(::NamedTuple{(:stepSize, :iter),Tuple{Float64,Int64}}, ::typeof(trainGamma), ::Array{Float64,2}, ::Array{Float64,1}, ::Int64, ::Array{Float64,2}, ::Float64) at ./none:0",
      " [3] top-level scope at In[108]:66"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "using AutoGrad\n",
    "using LinearAlgebra\n",
    "function gammaLoss0(x,y,alpha)\n",
    "    return 1/alpha * sum(y .* x .- norm(log.(complex(x))))\n",
    "end\n",
    "\n",
    "function gammaLoss(x,y,alpha,c,rho)\n",
    "#     return 1/alpha * sum(y .* (1./x) + log(x))\n",
    "    return 1/alpha * sum(y .* x .- log.(x)) + sum(rho .* (x .- c).^2)\n",
    "\n",
    "end\n",
    "\n",
    "function gammaLossG(x,y,alpha,c,rho)\n",
    "#     return 1/alpha * sum(y .* (1./x) + log(x))\n",
    "    return 1/alpha .* sum( y .- 1 ./ x) + sum(rho .* (x .- c).^2)\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "lossGammaGradient = AutoGrad.grad(gammaLoss);\n",
    "\n",
    "\n",
    "function trainGamma(x,y,alpha,c,rho;iter=500,stepSize = 0.02)\n",
    "\n",
    "     curFx = x;\n",
    "     iterCounter = 0;\n",
    "     gamma_ = stepSize;\n",
    "     precision_ = 1e-8;\n",
    "     previousStepSize = 1;\n",
    "\n",
    "\n",
    "    while previousStepSize > precision_\n",
    "        prevFx = curFx;\n",
    "        #curFx -= gamma_ .* lossGammaGradient(prevFx,y,alpha,c,rho);\n",
    "        curFx -= gamma_ .* gammaLossG(prevFx,y,alpha,c,rho);\n",
    "\n",
    "        previousStepSize = norm(curFx - prevFx);\n",
    "        iterCounter += 1;\n",
    "        if iterCounter > iter\n",
    "            break;\n",
    "        end\n",
    "#         if rem(iterCounter,50) == 1\n",
    "#             println(gammaLoss(curFx,y,alpha,c,rho));\n",
    "#         end\n",
    "    end\n",
    "    return curFx;\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function randomMatrixGamma(row::Int =1,col::Int=1,targetRank::Int=1,rate::Int=10)\n",
    "    p = Distributions.Poisson(rate)\n",
    "    baseMatrix = rand(p,row,targetRank)\n",
    "    for remaining = 1:col-targetRank\n",
    "        baseMatrix = hcat(baseMatrix,baseMatrix[:,StatsBase.sample(1:targetRank)])\n",
    "    end\n",
    "    return baseMatrix*1.0;\n",
    "end\n",
    "\n",
    "    \n",
    "p = Distributions.Gamma(5,0.5)\n",
    "data = rand(p,1000)*1.0\n",
    "\n",
    "#result = trainGamma(ones(1000,1)*2,data,5,ones(1000,1)*2.0,0.005,stepSize=0.02,iter=10000)\n",
    "\n",
    "result = trainGamma(ones(1000,1)*2,data,5,ones(1000,1)*2.0,0.005,stepSize=0.02,iter=10000)\n",
    "\n",
    "\n",
    "1 ./ result - data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
